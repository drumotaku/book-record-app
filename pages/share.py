# pages/share.py
import streamlit as st
import urllib.parse
from lib import get_conn, resolve_share, fetch_books_by_ids

st.set_page_config(page_title="å…±æœ‰ãƒ“ãƒ¥ãƒ¼", page_icon="ğŸ“š")
st.markdown('<meta name="robots" content="noindex">', unsafe_allow_html=True)
st.title("å…±æœ‰ãƒ“ãƒ¥ãƒ¼")

# ?token=... ã‚’å–å¾—
params = st.experimental_get_query_params()
token = params.get("token", [None])[0]
if not token:
    st.warning("å…±æœ‰ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# å…±æœ‰ã‚»ãƒƒãƒˆã‚’è§£æ±º
with get_conn() as conn:
    book_ids, err = resolve_share(conn, token)

if err == "not_found":
    st.error("å…±æœ‰ãƒªãƒ³ã‚¯ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"); st.stop()
if err == "revoked":
    st.error("ã“ã®å…±æœ‰ãƒªãƒ³ã‚¯ã¯å¤±åŠ¹ã—ã¦ã„ã¾ã™ã€‚"); st.stop()
if err == "expired":
    st.error("ã“ã®å…±æœ‰ãƒªãƒ³ã‚¯ã¯æœŸé™åˆ‡ã‚Œã§ã™ã€‚"); st.stop()
if not book_ids:
    st.info("å…±æœ‰ã‚»ãƒƒãƒˆã«æœ¬ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); st.stop()

# æœ¬æƒ…å ±ã‚’å–å¾—
with get_conn() as conn:
    books = fetch_books_by_ids(conn, book_ids)

def amazon_search_url(title: str, author: str = "") -> str:
    q = "+".join([s for s in [title, author] if s]).replace(" ", "+")
    return f"https://www.amazon.co.jp/s?k={urllib.parse.quote_plus(q)}"

# ä¸€è¦§ï¼‹Amazonãƒªãƒ³ã‚¯
for b in books:
    st.subheader(b["title"])
    st.write(f'è‘—è€…: {b.get("author","ä¸æ˜")}')
    if b.get("read_on"): st.caption(f'èª­äº†æ—¥: {b["read_on"]}')
    if b.get("rating") is not None: st.caption(f'è©•ä¾¡: {b["rating"]}')
    aurl = b.get("amazon_url") if b.get("amazon_url") else amazon_search_url(b["title"], b.get("author",""))
    st.link_button("Amazonã§è¦‹ã‚‹", aurl)
    st.divider()
